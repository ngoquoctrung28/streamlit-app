import streamlit as st
import pandas as pd
import os
from io import BytesIO
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import zipfile
import re
import json

# CSS t√πy ch·ªânh cho giao di·ªán chuy√™n nghi·ªáp
st.markdown("""
    <style>
    /* T√πy ch·ªânh m√†u s·∫Øc chung */
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
    }
    
    /* Ti√™u ƒë·ªÅ v√† header */
    h1, h2, h3 {
        color: #1f1f1f;
        font-weight: 600;
        margin-bottom: 1.5rem !important;
    }
    
    h3 {
        margin-top: 2rem !important;
        margin-bottom: 1rem !important;
    }
    
    h4 {
        margin-top: 1.5rem !important;
        margin-bottom: 0.75rem !important;
    }
    
    /* N·ªÅn v√† text */
    .stApp {
        background-color: #ffffff;
    }
    
    .stMarkdown {
        color: #1f1f1f;
    }
    
    /* Kho·∫£ng c√°ch gi·ªØa c√°c sections */
    .stMarkdown {
        margin-bottom: 1.5rem;
    }
    
    /* Form elements - tƒÉng kho·∫£ng c√°ch */
    .stTextInput > div > div > input,
    .stSelectbox > div > div > select,
    .stNumberInput > div > div > input {
        margin-bottom: 1.5rem;
    }
    
    /* Kho·∫£ng c√°ch cho c√°c widget */
    .element-container {
        margin-bottom: 1.5rem !important;
    }
    
    /* Text input spacing */
    div[data-testid="stTextInput"] {
        margin-bottom: 1.5rem !important;
    }
    
    /* Selectbox spacing */
    div[data-testid="stSelectbox"] {
        margin-bottom: 1.5rem !important;
    }
    
    /* Multiselect spacing */
    div[data-testid="stMultiSelect"] {
        margin-bottom: 1.5rem !important;
    }
    
    /* Number input spacing */
    div[data-testid="stNumberInput"] {
        margin-bottom: 1.5rem !important;
    }
    
    /* Button spacing */
    .stButton {
        margin-top: 0.5rem;
        margin-bottom: 1.5rem;
    }
    
    .stButton > button {
        background-color: #0d6efd;
        color: white;
        border-radius: 4px;
        border: none;
        font-weight: 500;
        padding: 0.5rem 1.5rem;
        margin-top: 0.5rem;
    }
    
    .stButton > button:hover {
        background-color: #0b5ed7;
    }
    
    /* Columns spacing */
    [data-testid="column"] {
        padding-left: 1rem;
        padding-right: 1rem;
    }
    
    [data-testid="column"]:first-child {
        padding-left: 0;
    }
    
    [data-testid="column"]:last-child {
        padding-right: 0;
    }
    
    /* Sidebar */
    .css-1d391kg {
        background-color: #f8f9fa;
    }
    
    /* Tab */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
        margin-bottom: 2rem;
    }
    
    .stTabs [data-baseweb="tab"] {
        color: #1f1f1f;
        font-weight: 500;
    }
    
    /* Info, success, warning boxes */
    .stInfo {
        background-color: #e7f3ff;
        border-left: 4px solid #0d6efd;
        padding: 1rem;
        margin-bottom: 1.5rem;
    }
    
    .stSuccess {
        background-color: #d1e7dd;
        border-left: 4px solid #198754;
        padding: 1rem;
        margin-bottom: 1.5rem;
    }
    
    .stWarning {
        background-color: #fff3cd;
        border-left: 4px solid #ffc107;
        padding: 1rem;
        margin-bottom: 1.5rem;
    }
    
    /* Subheader spacing */
    .stSubheader {
        margin-top: 2rem !important;
        margin-bottom: 1.5rem !important;
    }
    
    /* Metric spacing */
    [data-testid="stMetricValue"] {
        margin-bottom: 0.5rem;
    }
    
    /* Dataframe spacing */
    [data-testid="stDataFrame"] {
        margin-top: 1rem;
        margin-bottom: 1.5rem;
    }
    
    /* Expander spacing */
    [data-testid="stExpander"] {
        margin-top: 1rem;
        margin-bottom: 1.5rem;
    }
    
    /* Download button spacing */
    [data-testid="stDownloadButton"] {
        margin-top: 1rem;
        margin-bottom: 1rem;
    }
    </style>
""", unsafe_allow_html=True)

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="T·ªïng h·ª£p & Tra c·ª©u Excel",
    page_icon=None,
    layout="wide",
    initial_sidebar_state="expanded"
)

# Ti√™u ƒë·ªÅ ·ª©ng d·ª•ng
st.title("·ª®ng d·ª•ng T·ªïng h·ª£p & Tra c·ª©u Excel")
st.markdown("---")

# Kh·ªüi t·∫°o session state
if 'dataframes' not in st.session_state:
    st.session_state.dataframes = {}
if 'combined_df' not in st.session_state:
    st.session_state.combined_df = None
if 'search_results' not in st.session_state:
    st.session_state.search_results = None
if 'student_table' not in st.session_state:
    st.session_state.student_table = []
if 'files_loaded' not in st.session_state:
    # T·ª± ƒë·ªông load c√°c file ƒë√£ l∆∞u khi kh·ªüi ƒë·ªông (ch·ªâ load 1 l·∫ßn)
    st.session_state.files_loaded = False

UPLOADED_FILES_DIR = "uploaded_files"
BACKUP_DIR = "backup_data"
STUDENT_TABLE_FILE = os.path.join(BACKUP_DIR, "student_table.json")
COMBINED_DF_DIR = os.path.join(BACKUP_DIR, "combined_data")
EXPORTED_DATA_DIR = os.path.join(BACKUP_DIR, "exported_data")

def ensure_upload_dir():
    """T·∫°o th∆∞ m·ª•c l∆∞u file n·∫øu ch∆∞a t·ªìn t·∫°i"""
    if not os.path.exists(UPLOADED_FILES_DIR):
        os.makedirs(UPLOADED_FILES_DIR)

def ensure_backup_dirs():
    """T·∫°o c√°c th∆∞ m·ª•c backup n·∫øu ch∆∞a t·ªìn t·∫°i"""
    if not os.path.exists(BACKUP_DIR):
        os.makedirs(BACKUP_DIR)
    if not os.path.exists(COMBINED_DF_DIR):
        os.makedirs(COMBINED_DF_DIR)
    if not os.path.exists(EXPORTED_DATA_DIR):
        os.makedirs(EXPORTED_DATA_DIR)

def save_file_to_disk(file_bytes, filename):
    """L∆∞u file v√†o disk"""
    try:
        ensure_upload_dir()
        file_path = os.path.join(UPLOADED_FILES_DIR, filename)
        with open(file_path, 'wb') as f:
            f.write(file_bytes)
        return file_path
    except Exception as e:
        st.error(f"L·ªói khi l∆∞u file {filename}: {str(e)}")
        return None

def load_saved_files():
    """T·∫£i l·∫°i c√°c file ƒë√£ l∆∞u t·ª´ disk"""
    saved_files = {}
    ensure_upload_dir()
    
    try:
        if os.path.exists(UPLOADED_FILES_DIR):
            for filename in os.listdir(UPLOADED_FILES_DIR):
                if filename.endswith(('.xlsx', '.xls')):
                    file_path = os.path.join(UPLOADED_FILES_DIR, filename)
                    try:
                        sheets = load_excel_file(file_path)
                        if sheets:
                            saved_files[filename] = sheets
                    except Exception as e:
                        continue  # B·ªè qua file l·ªói
    except Exception as e:
        pass
    
    return saved_files

def delete_saved_file(filename):
    """X√≥a file ƒë√£ l∆∞u"""
    try:
        file_path = os.path.join(UPLOADED_FILES_DIR, filename)
        if os.path.exists(file_path):
            os.remove(file_path)
            return True
    except Exception as e:
        return False
    return False

def save_student_table():
    """L∆∞u b·∫£ng th√¥ng tin h·ªçc sinh v√†o file JSON"""
    try:
        ensure_backup_dirs()
        with open(STUDENT_TABLE_FILE, 'w', encoding='utf-8') as f:
            json.dump(st.session_state.student_table, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        return False

def load_student_table():
    """T·∫£i l·∫°i b·∫£ng th√¥ng tin h·ªçc sinh t·ª´ file JSON"""
    try:
        if os.path.exists(STUDENT_TABLE_FILE):
            with open(STUDENT_TABLE_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data
    except Exception as e:
        pass
    return []

def save_combined_df(df):
    """L∆∞u d·ªØ li·ªáu t·ªïng h·ª£p v·ªõi timestamp (tr√°nh ghi ƒë√®)"""
    try:
        ensure_backup_dirs()
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"combined_data_{timestamp}.xlsx"
        file_path = os.path.join(COMBINED_DF_DIR, filename)
        
        with pd.ExcelWriter(file_path, engine='xlsxwriter') as writer:
            df.to_excel(writer, index=False, sheet_name='D·ªØ li·ªáu t·ªïng h·ª£p')
        
        # L∆∞u file m·ªõi nh·∫•t (ƒë·ªÉ load l·∫°i nhanh)
        latest_file = os.path.join(COMBINED_DF_DIR, "latest_combined_data.xlsx")
        with pd.ExcelWriter(latest_file, engine='xlsxwriter') as writer:
            df.to_excel(writer, index=False, sheet_name='D·ªØ li·ªáu t·ªïng h·ª£p')
        
        return True
    except Exception as e:
        return False

def load_latest_combined_df():
    """T·∫£i l·∫°i d·ªØ li·ªáu t·ªïng h·ª£p m·ªõi nh·∫•t"""
    try:
        latest_file = os.path.join(COMBINED_DF_DIR, "latest_combined_data.xlsx")
        if os.path.exists(latest_file):
            df = pd.read_excel(latest_file, sheet_name='D·ªØ li·ªáu t·ªïng h·ª£p')
            return df
    except Exception as e:
        pass
    return None

def save_exported_data(df, export_type='excel'):
    """L∆∞u d·ªØ li·ªáu ƒë√£ xu·∫•t v·ªõi timestamp"""
    try:
        ensure_backup_dirs()
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        if export_type == 'excel':
            filename = f"exported_data_{timestamp}.xlsx"
            file_path = os.path.join(EXPORTED_DATA_DIR, filename)
            with pd.ExcelWriter(file_path, engine='xlsxwriter') as writer:
                df.to_excel(writer, index=False, sheet_name='D·ªØ li·ªáu xu·∫•t')
        else:
            filename = f"exported_data_{timestamp}.csv"
            file_path = os.path.join(EXPORTED_DATA_DIR, filename)
            df.to_csv(file_path, index=False, encoding='utf-8-sig')
        
        return True
    except Exception as e:
        return False

def load_excel_file(file):
    """ƒê·ªçc file Excel v√† tr·∫£ v·ªÅ dictionary c√°c sheet"""
    try:
        if isinstance(file, str):
            # N·∫øu l√† ƒë∆∞·ªùng d·∫´n file
            excel_file = pd.ExcelFile(file)
        else:
            # N·∫øu l√† file object t·ª´ upload
            excel_file = pd.ExcelFile(file)
        
        sheets_data = {}
        for sheet_name in excel_file.sheet_names:
            df = pd.read_excel(file, sheet_name=sheet_name)
            sheets_data[sheet_name] = df
        return sheets_data
    except Exception as e:
        if isinstance(file, str):
            st.error(f"L·ªói khi ƒë·ªçc file {file}: {str(e)}")
        else:
            st.error(f"L·ªói khi ƒë·ªçc file {file.name}: {str(e)}")
        return None

# T·ª± ƒë·ªông load c√°c file ƒë√£ l∆∞u khi kh·ªüi ƒë·ªông (sau khi c√°c h√†m ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a)
if not st.session_state.files_loaded:
    # Load file Excel ƒë√£ upload
    saved_files = load_saved_files()
    if saved_files:
        for file_name, sheets in saved_files.items():
            if file_name not in st.session_state.dataframes:
                st.session_state.dataframes[file_name] = sheets
    
    # Load b·∫£ng th√¥ng tin h·ªçc sinh ƒë√£ l∆∞u
    saved_table = load_student_table()
    if saved_table:
        st.session_state.student_table = saved_table
    
    # Load d·ªØ li·ªáu t·ªïng h·ª£p m·ªõi nh·∫•t
    saved_combined = load_latest_combined_df()
    if saved_combined is not None:
        st.session_state.combined_df = saved_combined
    
    st.session_state.files_loaded = True

def combine_dataframes(dataframes_dict, existing_df=None):
    """T·ªïng h·ª£p t·∫•t c·∫£ c√°c dataframe t·ª´ nhi·ªÅu file, c√≥ th·ªÉ append v√†o d·ªØ li·ªáu hi·ªán c√≥"""
    combined_data = []
    
    # N·∫øu c√≥ d·ªØ li·ªáu hi·ªán c√≥, th√™m v√†o danh s√°ch
    if existing_df is not None and not existing_df.empty:
        combined_data.append(existing_df)
    
    # Th√™m d·ªØ li·ªáu m·ªõi t·ª´ c√°c file
    for file_name, sheets in dataframes_dict.items():
        for sheet_name, df in sheets.items():
            df_copy = df.copy()
            df_copy['Ngu·ªìn_File'] = file_name
            df_copy['Sheet'] = sheet_name
            combined_data.append(df_copy)
    
    if combined_data:
        # Lo·∫°i b·ªè tr√πng l·∫∑p d·ª±a tr√™n t·∫•t c·∫£ c√°c c·ªôt (tr·ª´ Ngu·ªìn_File v√† Sheet c√≥ th·ªÉ kh√°c nhau)
        result = pd.concat(combined_data, ignore_index=True)
        # C√≥ th·ªÉ th√™m logic lo·∫°i b·ªè tr√πng l·∫∑p n·∫øu c·∫ßn
        return result
    return None

def search_dataframe(df, search_columns, search_value, match_type='contains'):
    """Tra c·ª©u d·ªØ li·ªáu trong dataframe"""
    if df is None or df.empty:
        return None
    
    try:
        results = pd.DataFrame()
        for col in search_columns:
            if col in df.columns:
                if match_type == 'contains':
                    mask = df[col].astype(str).str.contains(str(search_value), case=False, na=False)
                elif match_type == 'exact':
                    mask = df[col].astype(str).str.lower() == str(search_value).lower()
                elif match_type == 'starts_with':
                    mask = df[col].astype(str).str.lower().str.startswith(str(search_value).lower())
                elif match_type == 'ends_with':
                    mask = df[col].astype(str).str.lower().str.endswith(str(search_value).lower())
                else:
                    mask = pd.Series([False] * len(df))
                
                results = pd.concat([results, df[mask]], ignore_index=True)
        
        # Lo·∫°i b·ªè tr√πng l·∫∑p
        if not results.empty:
            results = results.drop_duplicates()
        
        return results
    except Exception as e:
        st.error(f"L·ªói khi tra c·ª©u: {str(e)}")
        return None

def export_to_excel(df, filename='bao_cao'):
    """Xu·∫•t dataframe ra file Excel"""
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='B√°o c√°o')
    output.seek(0)
    return output.getvalue()

def export_to_csv(df):
    """Xu·∫•t dataframe ra file CSV"""
    return df.to_csv(index=False).encode('utf-8-sig')

def normalize_file_name(file_name):
    """Chu·∫©n h√≥a t√™n file: b·ªè kho·∫£ng tr·∫Øng, chuy·ªÉn th√†nh lowercase"""
    return str(file_name).replace(' ', '').replace('\t', '').lower().strip()

def find_student_info_by_file(df, name, file_name):
    """T√¨m th√¥ng tin h·ªçc sinh d·ª±a tr√™n t√™n v√† t√™n file Excel"""
    if df is None or df.empty:
        return None
    
    try:
        # L·ªçc theo t√™n file (c·ªôt Ngu·ªìn_File)
        if 'Ngu·ªìn_File' in df.columns:
            # Chu·∫©n h√≥a t√™n file input (b·ªè kho·∫£ng tr·∫Øng, lowercase)
            normalized_input = normalize_file_name(file_name)
            
            # T√¨m file kh·ªõp (chu·∫©n h√≥a c·∫£ input v√† t√™n file trong database)
            def matches_file(nguon_file):
                normalized_file = normalize_file_name(nguon_file)
                return normalized_input in normalized_file or normalized_file in normalized_input
            
            file_mask = df['Ngu·ªìn_File'].astype(str).apply(matches_file)
            filtered_df = df[file_mask]
        else:
            filtered_df = df
        
        if filtered_df.empty:
            return None
        
        # T√¨m c√°c c·ªôt c√≥ th·ªÉ ch·ª©a t√™n
        name_columns = [col for col in filtered_df.columns if any(keyword in str(col).lower() for keyword in ['t√™n', 'name', 'h·ªç', 'ho ten', 'hoten'])]
        
        if not name_columns or not name:
            # N·∫øu kh√¥ng c√≥ t√™n, kh√¥ng tr·∫£ v·ªÅ d·ªØ li·ªáu (kh√¥ng kh·∫£ d·ª•ng)
            return None
        
        # Chu·∫©n h√≥a t√™n ƒë·ªÉ so s√°nh
        name_normalized = str(name).strip().lower()
        name_parts = name_normalized.split()
        
        # T√¨m ki·∫øm d·ª±a tr√™n t√™n - ∆∞u ti√™n kh·ªõp ch√≠nh x√°c h∆°n
        best_match = None
        best_score = 0
        
        for idx, row in filtered_df.iterrows():
            score = 0
            for col in name_columns:
                if col in filtered_df.columns:
                    row_name = str(row[col]).strip().lower() if pd.notna(row[col]) else ''
                    
                    # Kh·ªõp ch√≠nh x√°c ho√†n to√†n (ƒëi·ªÉm cao nh·∫•t)
                    if row_name == name_normalized:
                        score = 100
                        break
                    # Kh·ªõp ch√≠nh x√°c t·ª´ng t·ª´ (ƒëi·ªÉm cao)
                    elif name_normalized in row_name or row_name in name_normalized:
                        score = max(score, 80)
                    # Kh·ªõp ch·ª©a t·∫•t c·∫£ c√°c t·ª´ trong t√™n
                    elif all(part in row_name for part in name_parts if len(part) > 2):
                        score = max(score, 60)
                    # Kh·ªõp m·ªôt ph·∫ßn (ƒëi·ªÉm th·∫•p)
                    elif any(part in row_name for part in name_parts if len(part) > 2):
                        score = max(score, 30)
            
            if score > best_score:
                best_score = score
                best_match = row
        
        # N·∫øu t√¨m th·∫•y kh·ªõp t·ªët (score >= 30), tr·∫£ v·ªÅ k·∫øt qu·∫£
        if best_match is not None and best_score >= 30:
            return best_match
        
        # N·∫øu kh√¥ng t√¨m th·∫•y theo t√™n, tr·∫£ v·ªÅ None (kh√¥ng tr·∫£ v·ªÅ d√≤ng ƒë·∫ßu ti√™n n·ªØa)
        return None
    except Exception as e:
        return None

def check_duplicate_student(student_table, name, khoa, ngay_sinh=''):
    """Ki·ªÉm tra tr√πng d·ªØ li·ªáu h·ªçc sinh trong b·∫£ng"""
    if not student_table:
        return None, None
    
    name_normalized = str(name).strip().lower() if name else ''
    khoa_normalized = str(khoa).strip().lower() if khoa else ''
    ngay_sinh_normalized = str(ngay_sinh).strip().lower() if ngay_sinh else ''
    
    duplicates = []
    for idx, row in enumerate(student_table):
        row_name = str(row.get('H·ªç v√† t√™n', '')).strip().lower()
        row_khoa = str(row.get('Kho√°', '')).strip().lower()
        row_ngay_sinh = str(row.get('Ng√†y sinh', '')).strip().lower()
        
        # Ki·ªÉm tra tr√πng t√™n v√† kh√≥a
        if row_name == name_normalized and row_khoa == khoa_normalized:
            if row_ngay_sinh == ngay_sinh_normalized:
                # Tr√πng ho√†n to√†n
                duplicates.append({
                    'index': idx + 1,
                    'name': row.get('H·ªç v√† t√™n', ''),
                    'khoa': row.get('Kho√°', ''),
                    'ngay_sinh': row.get('Ng√†y sinh', ''),
                    'type': 'exact'  # Tr√πng ho√†n to√†n
                })
            else:
                # Tr√πng t√™n + kh√≥a nh∆∞ng kh√°c ng√†y sinh
                duplicates.append({
                    'index': idx + 1,
                    'name': row.get('H·ªç v√† t√™n', ''),
                    'khoa': row.get('Kho√°', ''),
                    'ngay_sinh': row.get('Ng√†y sinh', ''),
                    'type': 'different_dob'  # Tr√πng nh∆∞ng kh√°c ng√†y sinh
                })
    
    if duplicates:
        # T√¨m tr√πng ho√†n to√†n tr∆∞·ªõc
        exact_duplicate = [d for d in duplicates if d['type'] == 'exact']
        if exact_duplicate:
            return 'exact', exact_duplicate[0]
        # N·∫øu kh√¥ng c√≥ tr√πng ho√†n to√†n, tr·∫£ v·ªÅ tr√πng kh√°c ng√†y sinh
        return 'different_dob', duplicates[0]
    
    return None, None

def is_date_format(value):
    """Ki·ªÉm tra xem gi√° tr·ªã c√≥ ph·∫£i l√† ƒë·ªãnh d·∫°ng ng√†y th√°ng (dd/mm/yyyy, dd-mm-yyyy, etc.)"""
    if pd.isna(value):
        return False
    value_str = str(value).strip()
    # C√°c pattern ng√†y th√°ng ph·ªï bi·∫øn
    date_patterns = [
        r'^\d{1,2}[/-]\d{1,2}[/-]\d{4}$',  # dd/mm/yyyy, dd-mm-yyyy
        r'^\d{4}[/-]\d{1,2}[/-]\d{1,2}$',  # yyyy/mm/dd, yyyy-mm-dd
        r'^\d{1,2}[/-]\d{1,2}[/-]\d{2}$',  # dd/mm/yy, dd-mm-yy
    ]
    for pattern in date_patterns:
        if re.match(pattern, value_str):
            return True
    return False

def is_all_digits(value):
    """Ki·ªÉm tra xem gi√° tr·ªã c√≥ ph·∫£i l√† to√†n s·ªë (d√†i 9-12 ch·ªØ s·ªë - CCCD)"""
    if pd.isna(value):
        return False
    value_str = str(value).strip().replace('.', '').replace(',', '').replace(' ', '')
    # CCCD th∆∞·ªùng c√≥ 9-12 ch·ªØ s·ªë
    if value_str.isdigit() and 9 <= len(value_str) <= 12:
        return True
    return False

def extract_khoa_from_filename(file_name):
    """Tr√≠ch xu·∫•t kh√≥a t·ª´ t√™n file (v√≠ d·ª•: Bk16 t·ª´ bao cao 1- Bk16.xlsx)"""
    if not file_name:
        return ''
    
    file_str = str(file_name).strip()
    
    # T√¨m pattern nh∆∞ Bk16, BK16, bk16 (ch·ªØ c√°i + s·ªë)
    pattern = r'([A-Za-z]+\d+)'
    matches = re.findall(pattern, file_str)
    
    if matches:
        # L·∫•y match cu·ªëi c√πng (th∆∞·ªùng l√† kh√≥a)
        khoa = matches[-1]
        # Vi·∫øt hoa ch·ªØ c√°i ƒë·∫ßu
        if len(khoa) > 1:
            khoa = khoa[0].upper() + khoa[1:].lower()
        return khoa
    
    # N·∫øu kh√¥ng t√¨m th·∫•y, th·ª≠ t√¨m s·ªë (v√≠ d·ª•: 16, 2024)
    pattern_number = r'(\d{2,4})'
    matches_number = re.findall(pattern_number, file_str)
    if matches_number:
        return matches_number[-1]
    
    return ''

def capitalize_words(text):
    """Vi·∫øt hoa ch·ªØ c√°i ƒë·∫ßu c·ªßa m·ªói t·ª´"""
    if not text or pd.isna(text):
        return ''
    
    text_str = str(text).strip()
    if not text_str or text_str.lower() == 'nan':
        return ''
    
    # T√°ch th√†nh c√°c t·ª´ v√† vi·∫øt hoa ch·ªØ c√°i ƒë·∫ßu
    words = text_str.split()
    capitalized_words = []
    for word in words:
        if len(word) > 0:
            capitalized_words.append(word[0].upper() + word[1:].lower() if len(word) > 1 else word.upper())
        else:
            capitalized_words.append(word)
    
    return ' '.join(capitalized_words)

def map_column_names(df):
    """√Ånh x·∫° t√™n c·ªôt trong dataframe v·ªõi t√™n c·ªôt chu·∫©n d·ª±a tr√™n t√™n v√† n·ªôi dung"""
    mapping = {}
    column_mapping = {
        'ng√†y sinh': ['ng√†y sinh', 'ngay sinh', 'date of birth', 'dob', 'sinh ng√†y'],
        'cccd': ['cccd', 'cmnd', 'ch·ª©ng minh', 'chung minh', 's·ªë cmnd', 'so cmnd', 'cmnd/cccd', 'so cmnd/cccd', 's·ªë cccd', 'so cccd', 'cƒÉn c∆∞·ªõc'],
        'ƒë·ªãa ch·ªâ': ['ƒë·ªãa ch·ªâ', 'dia chi', 'address', 'ƒë·ªãa ƒëi·ªÉm', 'dia diem', 'n∆°i ·ªü', 'noi o'],
        'th·∫ßy': ['th·∫ßy', 'thay', 'gi√°o vi√™n', 'giao vien', 'teacher', 'gv', 'ng∆∞·ªùi h∆∞·ªõng d·∫´n', 'nguoi huong dan', 'gi·∫£ng vi√™n', 'giang vien', 'c√¥', 'co', 'th·∫ßy/c√¥', 'thay/co']
    }
    
    # L·∫•y sample d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch (l·∫•y 100 d√≤ng ƒë·∫ßu ho·∫∑c t·∫•t c·∫£ n·∫øu √≠t h∆°n)
    sample_size = min(100, len(df))
    sample_df = df.head(sample_size) if sample_size > 0 else df
    
    # T√¨m c·ªôt ng√†y sinh - ∆∞u ti√™n: t√™n c·ªôt c√≥ t·ª´ kh√≥a > gi√° tr·ªã c√≥ ƒë·ªãnh d·∫°ng ng√†y
    if 'ng√†y sinh' not in mapping:
        matched_cols_by_name = []
        for col in df.columns:
            if col in ['Ngu·ªìn_File', 'Sheet']:
                continue
            col_str = str(col).lower().strip()
            if any(keyword.lower().strip() in col_str for keyword in column_mapping['ng√†y sinh']):
                matched_cols_by_name.append(col)
        
        if matched_cols_by_name:
            mapping['ng√†y sinh'] = matched_cols_by_name[0]
        else:
            # T√¨m theo n·ªôi dung - c·ªôt c√≥ nhi·ªÅu gi√° tr·ªã ƒë·ªãnh d·∫°ng ng√†y nh·∫•t
            best_col = None
            best_count = 0
            for col in df.columns:
                if col in ['Ngu·ªìn_File', 'Sheet']:
                    continue
                date_count = sample_df[col].apply(is_date_format).sum()
                if date_count > best_count and date_count > sample_size * 0.3:  # √çt nh·∫•t 30% l√† ng√†y
                    best_count = date_count
                    best_col = col
            if best_col:
                mapping['ng√†y sinh'] = best_col
    
    # T√¨m c·ªôt CCCD - ∆∞u ti√™n: t√™n c·ªôt c√≥ t·ª´ kh√≥a > gi√° tr·ªã to√†n s·ªë (9-12 ch·ªØ s·ªë)
    if 'cccd' not in mapping:
        matched_cols_by_name = []
        for col in df.columns:
            if col in ['Ngu·ªìn_File', 'Sheet']:
                continue
            col_str = str(col).lower().strip()
            if any(keyword.lower().strip() in col_str for keyword in column_mapping['cccd']):
                matched_cols_by_name.append(col)
        
        if matched_cols_by_name:
            mapping['cccd'] = matched_cols_by_name[0]
        else:
            # T√¨m theo n·ªôi dung - c·ªôt c√≥ nhi·ªÅu gi√° tr·ªã to√†n s·ªë nh·∫•t
            best_col = None
            best_count = 0
            for col in df.columns:
                if col in ['Ngu·ªìn_File', 'Sheet', mapping.get('ng√†y sinh')]:
                    continue
                digit_count = sample_df[col].apply(is_all_digits).sum()
                if digit_count > best_count and digit_count > sample_size * 0.5:  # √çt nh·∫•t 50% l√† s·ªë
                    best_count = digit_count
                    best_col = col
            if best_col:
                mapping['cccd'] = best_col
    
    # T√¨m c·ªôt ƒë·ªãa ch·ªâ - ∆∞u ti√™n: c·ªôt ngay sau c·ªôt CCCD > t√™n c·ªôt c√≥ t·ª´ "ƒë·ªãa ch·ªâ" > c·ªôt c√≥ vƒÉn b·∫£n d√†i
    if 'ƒë·ªãa ch·ªâ' not in mapping:
        # ∆Øu ti√™n 1: T√¨m c·ªôt ngay sau c·ªôt CCCD (n·∫øu ƒë√£ t√¨m ƒë∆∞·ª£c CCCD)
        if 'cccd' in mapping:
            cccd_col = mapping['cccd']
            # L·∫•y danh s√°ch c·ªôt (lo·∫°i tr·ª´ Ngu·ªìn_File, Sheet)
            valid_cols = [col for col in df.columns if col not in ['Ngu·ªìn_File', 'Sheet']]
            if cccd_col in valid_cols:
                cccd_idx = valid_cols.index(cccd_col)
                # T√¨m c·ªôt ngay sau CCCD
                if cccd_idx + 1 < len(valid_cols):
                    next_col = valid_cols[cccd_idx + 1]
                    # Ki·ªÉm tra xem c·ªôt sau c√≥ ph·∫£i l√† "th·∫ßy" kh√¥ng
                    next_col_str = str(next_col).lower().strip()
                    is_thay_col = any(keyword.lower().strip() in next_col_str for keyword in column_mapping['th·∫ßy'])
                    if not is_thay_col and next_col != cccd_col:
                        # Lu√¥n l·∫•y c·ªôt ngay sau CCCD (kh√¥ng ki·ªÉm tra ƒë·ªô d√†i)
                        mapping['ƒë·ªãa ch·ªâ'] = next_col
        
        # N·∫øu ch∆∞a t√¨m ƒë∆∞·ª£c, th·ª≠ t√¨m theo t√™n c·ªôt
        if 'ƒë·ªãa ch·ªâ' not in mapping:
            matched_cols_by_name = []
            for col in df.columns:
                if col in ['Ngu·ªìn_File', 'Sheet', mapping.get('cccd')]:
                    continue
                col_str = str(col).lower().strip()
                # Ki·ªÉm tra xem c·ªôt c√≥ ph·∫£i l√† "th·∫ßy" kh√¥ng (tr√°nh nh·∫ßm l·∫´n)
                is_thay_col = any(keyword.lower().strip() in col_str for keyword in column_mapping['th·∫ßy'])
                if not is_thay_col and any(keyword.lower().strip() in col_str for keyword in column_mapping['ƒë·ªãa ch·ªâ']):
                    matched_cols_by_name.append(col)
            
            if matched_cols_by_name:
                mapping['ƒë·ªãa ch·ªâ'] = matched_cols_by_name[0]
        
        # N·∫øu v·∫´n ch∆∞a t√¨m ƒë∆∞·ª£c, t√¨m theo n·ªôi dung
        if 'ƒë·ªãa ch·ªâ' not in mapping:
            # T√¨m theo n·ªôi dung - ∆∞u ti√™n c·ªôt c√≥ ƒë·ªãa danh (ch·ªØ v√† s·ªë d√†i)
            best_col = None
            best_score = 0
            for col in df.columns:
                if col in ['Ngu·ªìn_File', 'Sheet', mapping.get('ng√†y sinh'), mapping.get('cccd'), mapping.get('th·∫ßy')]:
                    continue
                col_str = str(col).lower().strip()
                # Ki·ªÉm tra xem c·ªôt c√≥ ph·∫£i l√† "th·∫ßy" kh√¥ng
                is_thay_col = any(keyword.lower().strip() in col_str for keyword in column_mapping['th·∫ßy'])
                if not is_thay_col and df[col].dtype == 'object':
                    avg_length = sample_df[col].astype(str).str.len().mean()
                    if avg_length > 20:  # Trung b√¨nh > 20 k√Ω t·ª±
                        # Ki·ªÉm tra t·ª∑ l·ªá ch·ªØ v√† s·ªë (ƒë·ªãa danh th∆∞·ªùng c√≥ c·∫£ ch·ªØ v√† s·ªë)
                        sample_values = sample_df[col].astype(str).dropna().head(50)
                        if len(sample_values) > 0:
                            has_letters = sample_values.str.contains(r'[a-zA-Z√Ä-·ªπ]', na=False, regex=True).sum()
                            has_digits = sample_values.str.contains(r'\d', na=False, regex=True).sum()
                            # ƒêi·ªÉm cao h∆°n n·∫øu c√≥ c·∫£ ch·ªØ v√† s·ªë (ƒë·ªãa danh)
                            score = avg_length
                            if has_letters > len(sample_values) * 0.3 and has_digits > len(sample_values) * 0.2:
                                score = avg_length * 1.5  # TƒÉng ƒëi·ªÉm n·∫øu c√≥ c·∫£ ch·ªØ v√† s·ªë
                            else:
                                score = avg_length
                            
                            if score > best_score:
                                best_score = score
                                best_col = col
            if best_col:
                mapping['ƒë·ªãa ch·ªâ'] = best_col
    
    # T√¨m c·ªôt th·∫ßy - ch·ªâ d·ª±a v√†o t√™n c·ªôt, kh√¥ng d·ª±a v√†o n·ªôi dung
    if 'th·∫ßy' not in mapping:
        # T√¨m c·ªôt c√≥ t√™n kh·ªõp v·ªõi t·ª´ kh√≥a "th·∫ßy"
        best_thay_col = None
        best_score = 0
        
        for col in df.columns:
            if col in ['Ngu·ªìn_File', 'Sheet', mapping.get('ng√†y sinh'), mapping.get('cccd'), mapping.get('ƒë·ªãa ch·ªâ')]:
                continue
            col_str = str(col).lower().strip()
            
            # T√≠nh ƒëi·ªÉm d·ª±a tr√™n t·ª´ kh√≥a kh·ªõp
            for keyword in column_mapping['th·∫ßy']:
                keyword_lower = keyword.lower().strip()
                if keyword_lower in col_str:
                    # ƒêi·ªÉm cao h∆°n n·∫øu kh·ªõp ch√≠nh x√°c h∆°n
                    if col_str == keyword_lower:
                        score = 100
                    elif col_str.startswith(keyword_lower) or col_str.endswith(keyword_lower):
                        score = 80
                    else:
                        score = 50
                    
                    if score > best_score:
                        best_score = score
                        best_thay_col = col
                    break
        
        if best_thay_col:
            mapping['th·∫ßy'] = best_thay_col
    
    return mapping

# Sidebar - Upload files
with st.sidebar:
    st.header("Qu·∫£n l√Ω File")
    
    uploaded_files = st.file_uploader(
        "Ch·ªçn c√°c file Excel",
        type=['xlsx', 'xls'],
        accept_multiple_files=True
    )
    
    if uploaded_files:
        if st.button("T·∫£i l√™n & X·ª≠ l√Ω", type="primary"):
            with st.spinner("ƒêang x·ª≠ l√Ω files..."):
                for file in uploaded_files:
                    if file.name not in st.session_state.dataframes:
                        # ƒê·ªçc d·ªØ li·ªáu t·ª´ file
                        file_bytes = file.read()
                        file.seek(0)  # Reset file pointer
                        
                        sheets = load_excel_file(file)
                        if sheets:
                            # L∆∞u file v√†o disk
                            file_path = save_file_to_disk(file_bytes, file.name)
                            if file_path:
                                st.session_state.dataframes[file.name] = sheets
                                st.success(f"ƒê√£ t·∫£i v√† l∆∞u: {file.name}")
                            else:
                                # V·∫´n l∆∞u v√†o session state n·∫øu kh√¥ng l∆∞u ƒë∆∞·ª£c v√†o disk
                                st.session_state.dataframes[file.name] = sheets
                                st.success(f"ƒê√£ t·∫£i: {file.name}")
    
    # Hi·ªÉn th·ªã danh s√°ch file ƒë√£ t·∫£i
    if st.session_state.dataframes:
        st.markdown("---")
        st.subheader("Files ƒë√£ t·∫£i:")
        
        for file_name in list(st.session_state.dataframes.keys()):
            col_file, col_del = st.columns([4, 1])
            with col_file:
                st.write(f"‚Ä¢ {file_name}")
            with col_del:
                if st.button("üóëÔ∏è", key=f"del_{file_name}", help=f"X√≥a {file_name}"):
                    # X√≥a kh·ªèi session state
                    del st.session_state.dataframes[file_name]
                    # X√≥a kh·ªèi disk
                    delete_saved_file(file_name)
                    # Reset combined_df n·∫øu ƒëang d√πng
                    if st.session_state.combined_df is not None:
                        # Ki·ªÉm tra xem file b·ªã x√≥a c√≥ trong combined_df kh√¥ng
                        if 'Ngu·ªìn_File' in st.session_state.combined_df.columns:
                            st.session_state.combined_df = st.session_state.combined_df[
                                st.session_state.combined_df['Ngu·ªìn_File'] != file_name
                            ]
                            if st.session_state.combined_df.empty or len(st.session_state.combined_df) == 0:
                                st.session_state.combined_df = None
                            else:
                                # T·∫°o l·∫°i combined_df n·∫øu c√≤n file kh√°c
                                remaining_files = {k: v for k, v in st.session_state.dataframes.items() if k != file_name}
                                if remaining_files:
                                    st.session_state.combined_df = combine_dataframes(remaining_files)
                                else:
                                    st.session_state.combined_df = None
                    st.rerun()
        
        st.markdown("---")
        if st.button("X√≥a t·∫•t c·∫£", type="secondary"):
            # X√≥a t·∫•t c·∫£ file kh·ªèi disk
            for file_name in list(st.session_state.dataframes.keys()):
                delete_saved_file(file_name)
            
            # X√≥a kh·ªèi session state
            st.session_state.dataframes = {}
            st.session_state.combined_df = None
            st.session_state.search_results = None
            st.rerun()

# Main content
tab0, tab1, tab2, tab3, tab4 = st.tabs(["B·∫£ng Th√¥ng tin", "T·ªïng h·ª£p", "Tra c·ª©u", "Th·ªëng k√™", "Xu·∫•t b√°o c√°o"])

# Tab 0: B·∫£ng Th√¥ng tin
with tab0:
    st.header("B·∫£ng Th√¥ng tin H·ªçc sinh/Sinh vi√™n")
    
    if st.session_state.combined_df is not None:
        st.info("Nh·∫≠p t√™n v√† t√™n file Excel ƒë·ªÉ t·ª± ƒë·ªông ƒëi·ªÅn th√¥ng tin. ƒê·∫£m b·∫£o ƒë√£ t·ªïng h·ª£p d·ªØ li·ªáu ·ªü tab 'T·ªïng h·ª£p' tr∆∞·ªõc.")
        
        # T·∫°o c·ªôt mapping
        col_mapping = map_column_names(st.session_state.combined_df)
        
        # Kh·ªüi t·∫°o b·∫£ng n·∫øu ch∆∞a c√≥
        if len(st.session_state.student_table) == 0:
            st.session_state.student_table = [{
                'STT': 1,
                'H·ªç v√† t√™n': '',
                'Kho√°': '',
                'Ng√†y sinh': '',
                'CCCD': '',
                'ƒê·ªãa ch·ªâ': '',
                'Th·∫ßy': ''
            }]
        
        # Form ƒë·ªÉ th√™m/s·ª≠a d√≤ng
        st.markdown("### Nh·∫≠p th√¥ng tin")
        st.markdown("")  # Kho·∫£ng c√°ch
        
        # S·ª≠ d·ª•ng st.form ƒë·ªÉ c√≥ th·ªÉ b·∫•m Enter ƒë·ªÉ submit
        with st.form("form_tim_them", clear_on_submit=False):
            col_form1, col_form2 = st.columns(2)
            
            with col_form1:
                new_name = st.text_input("H·ªç v√† t√™n:", key="new_name_form", placeholder="V√≠ d·ª•: Nguy·ªÖn VƒÉn A")
                # Hi·ªÉn th·ªã l·ªói tr√πng d·ªØ li·ªáu (n·∫øu c√≥)
                if 'duplicate_error' in st.session_state:
                    st.markdown(f"<div style='color: #dc3545; font-size: 0.9em; margin-top: -1rem; margin-bottom: 1rem;'>{st.session_state.duplicate_error}</div>", unsafe_allow_html=True)
                    del st.session_state.duplicate_error
            with col_form2:
                new_file = st.text_input("Kh√≥a:", key="new_file_form", placeholder="V√≠ d·ª•: Bk16, B01K14", help="Nh·∫≠p kh√≥a (c√≥ th·ªÉ c√≥ kho·∫£ng tr·∫Øng ho·∫∑c vi·∫øt hoa/th∆∞·ªùng). B·∫•m Enter ƒë·ªÉ t·ª± ƒë·ªông t√¨m v√† th√™m.")
            
            # N√∫t submit (s·∫Ω ƒë∆∞·ª£c trigger khi b·∫•m Enter)
            submitted = st.form_submit_button("T√¨m v√† Th√™m (ho·∫∑c b·∫•m Enter)", type="primary", use_container_width=True)
        
        # X·ª≠ l√Ω khi form ƒë∆∞·ª£c submit (b·∫•m Enter ho·∫∑c b·∫•m n√∫t)
        if submitted:
            if new_file:
                # T√¨m th√¥ng tin theo t√™n file (v√† t√™n n·∫øu c√≥)
                    found_info = find_student_info_by_file(st.session_state.combined_df, new_name, new_file)
                    
                    if found_info is not None:
                        # L·∫•y th√¥ng tin t·ª´ k·∫øt qu·∫£ t√¨m ƒë∆∞·ª£c
                        ngay_sinh = ''
                        cccd = ''
                        dia_chi = ''
                        thay = ''
                        
                        # L·∫•y th√¥ng tin t·ª´ mapping cho ng√†y sinh
                        if 'ng√†y sinh' in col_mapping:
                            col_name = col_mapping['ng√†y sinh']
                            if col_name in found_info.index:
                                value = found_info[col_name]
                                if pd.notna(value):
                                    ngay_sinh = str(value).strip()
                                    if ngay_sinh.lower() == 'nan':
                                        ngay_sinh = ''
                        
                        # L·∫•y CCCD t·ª´ c·ªôt th·ª© 4 (sau khi lo·∫°i tr·ª´ Ngu·ªìn_File, Sheet)
                        # L·∫•y danh s√°ch c·ªôt h·ª£p l·ªá (lo·∫°i tr·ª´ Ngu·ªìn_File, Sheet)
                        valid_cols = [col for col in found_info.index if col not in ['Ngu·ªìn_File', 'Sheet']]
                        if len(valid_cols) >= 4:
                            col_cccd = valid_cols[3]  # C·ªôt th·ª© 4 (index 3)
                            if col_cccd in found_info.index:
                                value = found_info[col_cccd]
                                if pd.notna(value):
                                    cccd = str(value).strip()
                                    if cccd.lower() != 'nan':
                                        cccd = cccd
                        
                        # L·∫•y ƒê·ªãa ch·ªâ t·ª´ c·ªôt th·ª© 5 (sau khi lo·∫°i tr·ª´ Ngu·ªìn_File, Sheet)
                        if len(valid_cols) >= 5:
                            col_dia_chi = valid_cols[4]  # C·ªôt th·ª© 5 (index 4)
                            if col_dia_chi in found_info.index:
                                value = found_info[col_dia_chi]
                                if pd.notna(value):
                                    dia_chi = str(value).strip()
                                    if dia_chi.lower() != 'nan':
                                        dia_chi = dia_chi
                        
                        # Kh√¥ng t·ª± ƒë·ªông ƒëi·ªÅn c·ªôt Th·∫ßy - ƒë·ªÉ ng∆∞·ªùi d√πng t·ª± nh·∫≠p
                        thay = ''
                        
                        # L·∫•y t√™n t·ª´ d·ªØ li·ªáu t√¨m ƒë∆∞·ª£c (n·∫øu c√≥)
                        display_name = new_name if new_name else ''
                        if not display_name and 'ng√†y sinh' in col_mapping:
                            # Th·ª≠ l·∫•y t√™n t·ª´ c·ªôt t√™n n·∫øu c√≥
                            name_cols = [col for col in found_info.index if any(kw in str(col).lower() for kw in ['t√™n', 'name', 'h·ªç'])]
                            if name_cols:
                                display_name = str(found_info[name_cols[0]]) if pd.notna(found_info[name_cols[0]]) else ''
                        
                        # L·∫•y kh√≥a tr·ª±c ti·∫øp t·ª´ input v√† vi·∫øt hoa ch·ªØ c√°i ƒë·∫ßu
                        khoa = new_file.strip() if new_file else ''
                        if khoa:
                            # Vi·∫øt hoa ch·ªØ c√°i ƒë·∫ßu, gi·ªØ nguy√™n ph·∫ßn c√≤n l·∫°i
                            khoa = khoa[0].upper() + khoa[1:] if len(khoa) > 1 else khoa.upper()
                        
                        # Vi·∫øt hoa ch·ªØ c√°i ƒë·∫ßu cho c√°c gi√° tr·ªã (tr·ª´ Th·∫ßy - kh√¥ng ƒëi·ªÅn t·ª± ƒë·ªông)
                        display_name = capitalize_words(display_name if display_name else new_name)
                        dia_chi = capitalize_words(dia_chi)
                        
                        # Ki·ªÉm tra tr√πng d·ªØ li·ªáu
                        dup_type, dup_info = check_duplicate_student(
                            st.session_state.student_table, 
                            display_name, 
                            khoa, 
                            ngay_sinh
                        )
                        
                        if dup_type == 'exact':
                            # Tr√πng ho√†n to√†n
                            error_msg = f"‚ö†Ô∏è Tr√πng d·ªØ li·ªáu! H·ªçc vi√™n '{display_name}' (Kh√≥a: {khoa}, Ng√†y sinh: {ngay_sinh}) ƒë√£ t·ªìn t·∫°i ·ªü d√≤ng STT {dup_info['index']}."
                            st.session_state.duplicate_error = error_msg
                            st.error(error_msg)
                            st.rerun()
                        elif dup_type == 'different_dob':
                            # Tr√πng t√™n + kh√≥a nh∆∞ng kh√°c ng√†y sinh
                            error_msg = f"‚ö†Ô∏è Tr√πng d·ªØ li·ªáu! H·ªçc vi√™n '{display_name}' (Kh√≥a: {khoa}) ƒë√£ t·ªìn t·∫°i ·ªü d√≤ng STT {dup_info['index']} v·ªõi ng√†y sinh: {dup_info['ngay_sinh']}. Ng√†y sinh hi·ªán t·∫°i: {ngay_sinh if ngay_sinh else '(tr·ªëng)'}."
                            st.session_state.duplicate_error = error_msg
                            st.error(error_msg)
                            st.rerun()
                        else:
                            # Kh√¥ng tr√πng, th√™m d√≤ng m·ªõi
                            new_stt = len(st.session_state.student_table) + 1
                            st.session_state.student_table.append({
                                'STT': new_stt,
                                'H·ªç v√† t√™n': display_name,
                                'Kho√°': khoa,
                                'Ng√†y sinh': ngay_sinh,
                                'CCCD': cccd,
                                'ƒê·ªãa ch·ªâ': dia_chi,
                                'Th·∫ßy': ''  # Kh√¥ng t·ª± ƒë·ªông ƒëi·ªÅn - ƒë·ªÉ ng∆∞·ªùi d√πng t·ª± nh·∫≠p
                            })
                            # T·ª± ƒë·ªông sao l∆∞u
                            save_student_table()
                            st.success(f"ƒê√£ t√¨m th·∫•y v√† th√™m th√¥ng tin t·ª´ file {new_file}!")
                            st.rerun()
                    else:
                        # Kh√¥ng t√¨m th·∫•y - ch·ªâ b√°o, KH√îNG add v√†o b·∫£ng
                        st.warning(f"Kh√¥ng t√¨m th·∫•y th√¥ng tin h·ªçc vi√™n '{new_name if new_name else '(kh√¥ng c√≥ t√™n)'}' v·ªõi kh√≥a {new_file}!")
                        st.info("Vui l√≤ng ki·ªÉm tra l·∫°i t√™n h·ªçc vi√™n v√† kh√≥a.")
            else:
                st.warning("Vui l√≤ng nh·∫≠p kh√≥a!")
        
        # C√°c n√∫t kh√°c
        st.markdown("")  # Kho·∫£ng c√°ch
        col_btn2, col_btn3 = st.columns(2)
        with col_btn2:
            if st.button("Th√™m D√≤ng Tr·ªëng"):
                new_stt = len(st.session_state.student_table) + 1
                st.session_state.student_table.append({
                    'STT': new_stt,
                    'H·ªç v√† t√™n': '',
                    'Kho√°': '',
                    'Ng√†y sinh': '',
                    'CCCD': '',
                    'ƒê·ªãa ch·ªâ': '',
                    'Th·∫ßy': ''
                })
                # T·ª± ƒë·ªông sao l∆∞u
                save_student_table()
                st.rerun()
        
        with col_btn3:
            if st.button("X√≥a T·∫•t c·∫£"):
                st.session_state.student_table = []
                # T·ª± ƒë·ªông sao l∆∞u
                save_student_table()
                st.rerun()
        
        st.markdown("---")
        
        # Hi·ªÉn th·ªã b·∫£ng
        if st.session_state.student_table:
            st.markdown("### B·∫£ng Th√¥ng tin")
            
            # C·∫≠p nh·∫≠t STT
            for i, row in enumerate(st.session_state.student_table):
                row['STT'] = i + 1
            
            # Chuy·ªÉn ƒë·ªïi sang DataFrame ƒë·ªÉ hi·ªÉn th·ªã
            df_display = pd.DataFrame(st.session_state.student_table)
            
            # Lo·∫°i b·ªè c·ªôt not_found kh·ªèi hi·ªÉn th·ªã (n·∫øu c√≥)
            display_cols = [col for col in df_display.columns if col != 'not_found']
            df_to_show = df_display[display_cols].copy()
            
            # C·∫•u h√¨nh c·ªôt cho data_editor - ch·ªâ cho ph√©p ch·ªânh s·ª≠a c·ªôt "Th·∫ßy"
            column_config = {}
            for col in df_to_show.columns:
                if col == 'Th·∫ßy':
                    column_config[col] = st.column_config.TextColumn(
                        col,
                        help="C√≥ th·ªÉ ch·ªânh s·ª≠a th√¥ng tin",
                        default=""
                    )
                elif col == 'STT':
                    column_config[col] = st.column_config.NumberColumn(
                        col,
                        disabled=True
                    )
                else:
                    column_config[col] = st.column_config.TextColumn(
                        col,
                        disabled=True
                    )
            
            # Hi·ªÉn th·ªã v·ªõi data_editor ƒë·ªÉ cho ph√©p ch·ªânh s·ª≠a c·ªôt Th·∫ßy
            edited_df = st.data_editor(
                df_to_show,
                column_config=column_config,
                use_container_width=True,
                height=400,
                key="student_table_editor"
            )
            
            # C·∫≠p nh·∫≠t l·∫°i session_state n·∫øu c√≥ thay ƒë·ªïi
            if not edited_df.equals(df_to_show):
                # C·∫≠p nh·∫≠t d·ªØ li·ªáu t·ª´ edited_df v·ªÅ session_state
                for idx in range(min(len(edited_df), len(st.session_state.student_table))):
                    if 'Th·∫ßy' in edited_df.columns:
                        new_value = edited_df.iloc[idx]['Th·∫ßy']
                        if pd.notna(new_value):
                            st.session_state.student_table[idx]['Th·∫ßy'] = str(new_value).strip()
                        else:
                            st.session_state.student_table[idx]['Th·∫ßy'] = ''
                # T·ª± ƒë·ªông sao l∆∞u
                save_student_table()
                st.rerun()
            
            # Ch·ª©c nƒÉng c·∫≠p nh·∫≠t l·∫°i th√¥ng tin
            st.markdown("#### C·∫≠p nh·∫≠t l·∫°i th√¥ng tin")
            st.markdown("")  # Kho·∫£ng c√°ch
            col_update1, col_update2 = st.columns([3, 1])
            with col_update1:
                st.info("Ch·ª©c nƒÉng n√†y s·∫Ω t·ª± ƒë·ªông t√¨m l·∫°i th√¥ng tin t·ª´ Excel v√† c·∫≠p nh·∫≠t l·∫°i c√°c tr∆∞·ªùng: Ng√†y sinh, CCCD, ƒê·ªãa ch·ªâ (d·ª±a tr√™n t√™n v√† kh√≥a).")
            with col_update2:
                if st.button("C·∫≠p nh·∫≠t l·∫°i t·∫•t c·∫£", type="primary"):
                    updated_count = 0
                    not_found_count = 0
                    
                    with st.spinner("ƒêang c·∫≠p nh·∫≠t th√¥ng tin..."):
                        for idx, row in enumerate(st.session_state.student_table):
                            student_name = row.get('H·ªç v√† t√™n', '').strip()
                            student_khoa = row.get('Kho√°', '').strip()
                            
                            if not student_name or not student_khoa:
                                continue
                            
                            # T√¨m file Excel d·ª±a tr√™n kh√≥a
                            # Kh√≥a th∆∞·ªùng ch·ª©a t√™n file (v√≠ d·ª•: "Bk16" trong "bao cao 1- Bk16.xlsx")
                            found_info = None
                            
                            # Th·ª≠ t√¨m trong t·∫•t c·∫£ c√°c file (chu·∫©n h√≥a ƒë·ªÉ b·ªè kho·∫£ng tr·∫Øng, kh√¥ng ph√¢n bi·ªát hoa th∆∞·ªùng)
                            normalized_khoa = normalize_file_name(student_khoa)
                            for file_name in st.session_state.dataframes.keys():
                                normalized_file = normalize_file_name(file_name)
                                if normalized_khoa in normalized_file or normalized_file in normalized_khoa:
                                    # T√¨m th√¥ng tin h·ªçc vi√™n trong file n√†y
                                    found_info = find_student_info_by_file(
                                        st.session_state.combined_df, 
                                        student_name, 
                                        file_name
                                    )
                                    if found_info is not None:
                                        break
                            
                            # N·∫øu kh√¥ng t√¨m th·∫•y theo kh√≥a, th·ª≠ t√¨m trong t·∫•t c·∫£ file
                            if found_info is None:
                                for file_name in st.session_state.dataframes.keys():
                                    found_info = find_student_info_by_file(
                                        st.session_state.combined_df, 
                                        student_name, 
                                        file_name
                                    )
                                    if found_info is not None:
                                        break
                            
                            if found_info is not None:
                                # C·∫≠p nh·∫≠t th√¥ng tin t·ª´ Excel
                                # L·∫•y th√¥ng tin t·ª´ mapping cho ng√†y sinh
                                if 'ng√†y sinh' in col_mapping:
                                    col_name = col_mapping['ng√†y sinh']
                                    if col_name in found_info.index:
                                        value = found_info[col_name]
                                        if pd.notna(value):
                                            new_ngay_sinh = str(value).strip()
                                            if new_ngay_sinh.lower() != 'nan':
                                                st.session_state.student_table[idx]['Ng√†y sinh'] = new_ngay_sinh
                                
                                # L·∫•y CCCD t·ª´ c·ªôt th·ª© 4 (sau khi lo·∫°i tr·ª´ Ngu·ªìn_File, Sheet)
                                valid_cols = [col for col in found_info.index if col not in ['Ngu·ªìn_File', 'Sheet']]
                                if len(valid_cols) >= 4:
                                    col_cccd = valid_cols[3]  # C·ªôt th·ª© 4 (index 3)
                                    if col_cccd in found_info.index:
                                        value = found_info[col_cccd]
                                        if pd.notna(value):
                                            new_cccd = str(value).strip()
                                            if new_cccd.lower() != 'nan':
                                                st.session_state.student_table[idx]['CCCD'] = new_cccd
                                
                                # L·∫•y ƒê·ªãa ch·ªâ t·ª´ c·ªôt th·ª© 5 (sau khi lo·∫°i tr·ª´ Ngu·ªìn_File, Sheet)
                                if len(valid_cols) >= 5:
                                    col_dia_chi = valid_cols[4]  # C·ªôt th·ª© 5 (index 4)
                                    if col_dia_chi in found_info.index:
                                        value = found_info[col_dia_chi]
                                        if pd.notna(value):
                                            new_dia_chi = str(value).strip()
                                            if new_dia_chi.lower() != 'nan':
                                                new_dia_chi = capitalize_words(new_dia_chi)
                                                st.session_state.student_table[idx]['ƒê·ªãa ch·ªâ'] = new_dia_chi
                                
                                updated_count += 1
                            else:
                                not_found_count += 1
                    
                    # T·ª± ƒë·ªông sao l∆∞u
                    save_student_table()
                    
                    if updated_count > 0:
                        st.success(f"ƒê√£ c·∫≠p nh·∫≠t {updated_count} h·ªçc vi√™n!")
                    if not_found_count > 0:
                        st.warning(f"Kh√¥ng t√¨m th·∫•y th√¥ng tin cho {not_found_count} h·ªçc vi√™n.")
                    st.rerun()
            
            st.markdown("---")
            
            # Ch·ª©c nƒÉng x√≥a t·ª´ng d√≤ng
            st.markdown("#### X√≥a d√≤ng")
            if len(st.session_state.student_table) > 0:
                delete_col1, delete_col2 = st.columns([3, 1])
                with delete_col1:
                    delete_index = st.number_input(
                        "Nh·∫≠p STT c·ªßa d√≤ng c·∫ßn x√≥a:",
                        min_value=1,
                        max_value=len(st.session_state.student_table),
                        value=1,
                        step=1,
                        key="delete_index"
                    )
                with delete_col2:
                    st.markdown("<br>", unsafe_allow_html=True)
                    if st.button("X√≥a d√≤ng n√†y", type="secondary"):
                        if 1 <= delete_index <= len(st.session_state.student_table):
                            st.session_state.student_table.pop(delete_index - 1)
                            # T·ª± ƒë·ªông sao l∆∞u
                            save_student_table()
                            st.success(f"ƒê√£ x√≥a d√≤ng {delete_index}!")
                            st.rerun()
            
            # T√πy ch·ªçn xu·∫•t
            st.markdown("---")
            st.markdown("### Xu·∫•t b√°o c√°o")
            export_df = pd.DataFrame(st.session_state.student_table)
            
            col_exp1, col_exp2 = st.columns(2)
            
            with col_exp1:
                file_data_excel = export_to_excel(export_df, f"bang_thong_tin_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
                # T·ª± ƒë·ªông sao l∆∞u d·ªØ li·ªáu xu·∫•t
                save_exported_data(export_df, 'excel')
                st.download_button(
                    label="T·∫£i file Excel (.xlsx)",
                    data=file_data_excel,
                    file_name=f"bang_thong_tin_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
            
            with col_exp2:
                file_data_csv = export_to_csv(export_df)
                # T·ª± ƒë·ªông sao l∆∞u d·ªØ li·ªáu xu·∫•t
                save_exported_data(export_df, 'csv')
                st.download_button(
                    label="T·∫£i file CSV (.csv)",
                    data=file_data_csv,
                    file_name=f"bang_thong_tin_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    use_container_width=True
                )
        else:
            st.info("B·∫£ng tr·ªëng. H√£y th√™m d√≤ng m·ªõi ƒë·ªÉ b·∫Øt ƒë·∫ßu!")
    elif st.session_state.dataframes:
        st.warning("Vui l√≤ng t·ªïng h·ª£p d·ªØ li·ªáu ·ªü tab 'T·ªïng h·ª£p' tr∆∞·ªõc khi s·ª≠ d·ª•ng ch·ª©c nƒÉng n√†y!")
    else:
        st.info("Vui l√≤ng t·∫£i l√™n c√°c file Excel ·ªü sidebar v√† t·ªïng h·ª£p d·ªØ li·ªáu tr∆∞·ªõc!")

# Tab 1: T·ªïng h·ª£p
with tab1:
    st.header("T·ªïng h·ª£p D·ªØ li·ªáu")
    
    if st.session_state.dataframes:
        if st.button("T·ªïng h·ª£p T·∫•t c·∫£", type="primary"):
            with st.spinner("ƒêang t·ªïng h·ª£p d·ªØ li·ªáu..."):
                # T·ªïng h·ª£p th√™m v√†o d·ªØ li·ªáu hi·ªán c√≥ (n·∫øu c√≥)
                st.session_state.combined_df = combine_dataframes(
                    st.session_state.dataframes, 
                    existing_df=st.session_state.combined_df
                )
                if st.session_state.combined_df is not None:
                    # T·ª± ƒë·ªông sao l∆∞u d·ªØ li·ªáu t·ªïng h·ª£p (tr√°nh ghi ƒë√®)
                    save_combined_df(st.session_state.combined_df)
                    st.success(f"ƒê√£ t·ªïng h·ª£p {len(st.session_state.combined_df)} d√≤ng d·ªØ li·ªáu v√† t·ª± ƒë·ªông sao l∆∞u!")
        
        if st.session_state.combined_df is not None:
            st.subheader("D·ªØ li·ªáu t·ªïng h·ª£p")
            st.markdown("")  # Kho·∫£ng c√°ch
            
            # Hi·ªÉn th·ªã th√¥ng tin c∆° b·∫£n
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("T·ªïng s·ªë d√≤ng", len(st.session_state.combined_df))
            with col2:
                st.metric("T·ªïng s·ªë c·ªôt", len(st.session_state.combined_df.columns))
            with col3:
                st.metric("S·ªë file ngu·ªìn", st.session_state.combined_df['Ngu·ªìn_File'].nunique())
            
            st.markdown("")  # Kho·∫£ng c√°ch
            
            # L·ªçc v√† hi·ªÉn th·ªã d·ªØ li·ªáu
            st.markdown("### L·ªçc d·ªØ li·ªáu")
            st.markdown("")  # Kho·∫£ng c√°ch
            
            filter_col1, filter_col2 = st.columns(2)
            
            with filter_col1:
                file_filter = st.multiselect(
                    "Ch·ªçn file ngu·ªìn",
                    options=st.session_state.combined_df['Ngu·ªìn_File'].unique(),
                    default=st.session_state.combined_df['Ngu·ªìn_File'].unique()
                )
            
            with filter_col2:
                sheet_filter = st.multiselect(
                    "Ch·ªçn sheet",
                    options=st.session_state.combined_df['Sheet'].unique(),
                    default=st.session_state.combined_df['Sheet'].unique()
                )
            
            filtered_df = st.session_state.combined_df[
                (st.session_state.combined_df['Ngu·ªìn_File'].isin(file_filter)) &
                (st.session_state.combined_df['Sheet'].isin(sheet_filter))
            ]
            
            st.dataframe(filtered_df, use_container_width=True, height=400)
            
            # T√πy ch·ªçn hi·ªÉn th·ªã th√™m
            with st.expander("Xem chi ti·∫øt c·∫•u tr√∫c d·ªØ li·ªáu"):
                st.write("**Th√¥ng tin c·ªôt:**")
                col_info = pd.DataFrame({
                    'C·ªôt': filtered_df.columns,
                    'Ki·ªÉu d·ªØ li·ªáu': [str(dtype) for dtype in filtered_df.dtypes],
                    'Gi√° tr·ªã null': filtered_df.isnull().sum().values,
                    'Gi√° tr·ªã duy nh·∫•t': [filtered_df[col].nunique() for col in filtered_df.columns]
                })
                st.dataframe(col_info, use_container_width=True)
    else:
        st.info("Vui l√≤ng t·∫£i l√™n c√°c file Excel ·ªü sidebar ƒë·ªÉ b·∫Øt ƒë·∫ßu!")

# Tab 2: Tra c·ª©u
with tab2:
    st.header("Tra c·ª©u Th√¥ng tin")
    
    if st.session_state.combined_df is not None:
        search_col1, search_col2 = st.columns([2, 1])
        
        with search_col1:
            search_value = st.text_input("Nh·∫≠p t·ª´ kh√≥a tra c·ª©u:", placeholder="V√≠ d·ª•: t√™n, m√£ s·ªë, v.v.")
        
        with search_col2:
            match_type = st.selectbox(
                "Ki·ªÉu t√¨m ki·∫øm:",
                options=['contains', 'exact', 'starts_with', 'ends_with'],
                format_func=lambda x: {
                    'contains': 'Ch·ª©a',
                    'exact': 'Ch√≠nh x√°c',
                    'starts_with': 'B·∫Øt ƒë·∫ßu v·ªõi',
                    'ends_with': 'K·∫øt th√∫c b·∫±ng'
                }[x]
            )
        
        # Ch·ªçn c·ªôt ƒë·ªÉ tra c·ª©u
        available_columns = [col for col in st.session_state.combined_df.columns 
                           if col not in ['Ngu·ªìn_File', 'Sheet']]
        search_columns = st.multiselect(
            "Ch·ªçn c·ªôt ƒë·ªÉ tra c·ª©u:",
            options=available_columns,
            default=available_columns[:3] if len(available_columns) >= 3 else available_columns
        )
        
        if st.button("T√¨m ki·∫øm", type="primary"):
            if search_value and search_columns:
                with st.spinner("ƒêang tra c·ª©u..."):
                    results = search_dataframe(
                        st.session_state.combined_df,
                        search_columns,
                        search_value,
                        match_type
                    )
                    st.session_state.search_results = results
                    
                    if results is not None and not results.empty:
                        st.success(f"T√¨m th·∫•y {len(results)} k·∫øt qu·∫£!")
                    else:
                        st.warning("Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ n√†o!")
            else:
                st.warning("Vui l√≤ng nh·∫≠p t·ª´ kh√≥a v√† ch·ªçn √≠t nh·∫•t m·ªôt c·ªôt!")
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£ tra c·ª©u
        if st.session_state.search_results is not None and not st.session_state.search_results.empty:
            st.markdown("### K·∫øt qu·∫£ tra c·ª©u")
            
            col1, col2 = st.columns([3, 1])
            with col1:
                st.dataframe(st.session_state.search_results, use_container_width=True, height=400)
            
            with col2:
                st.metric("S·ªë k·∫øt qu·∫£", len(st.session_state.search_results))
                
                # Th·ªëng k√™ nhanh
                st.markdown("**Theo ngu·ªìn:**")
                source_counts = st.session_state.search_results['Ngu·ªìn_File'].value_counts()
                for source, count in source_counts.items():
                    st.write(f"‚Ä¢ {source}: {count}")
    elif st.session_state.dataframes:
        st.info("Vui l√≤ng t·ªïng h·ª£p d·ªØ li·ªáu tr∆∞·ªõc ·ªü tab 'T·ªïng h·ª£p'!")
    else:
        st.info("Vui l√≤ng t·∫£i l√™n c√°c file Excel ·ªü sidebar ƒë·ªÉ b·∫Øt ƒë·∫ßu!")

# Tab 3: Th·ªëng k√™
with tab3:
    st.header("Th·ªëng k√™ & Ph√¢n t√≠ch")
    
    if st.session_state.combined_df is not None:
        st.subheader("Th·ªëng k√™ m√¥ t·∫£")
        
        # Ch·ªçn c·ªôt s·ªë ƒë·ªÉ th·ªëng k√™
        numeric_columns = st.session_state.combined_df.select_dtypes(include=['number']).columns.tolist()
        
        if numeric_columns:
            selected_numeric_col = st.selectbox("Ch·ªçn c·ªôt s·ªë ƒë·ªÉ ph√¢n t√≠ch:", numeric_columns)
            
            if selected_numeric_col:
                col1, col2 = st.columns(2)
                
                with col1:
                    # Th·ªëng k√™ c∆° b·∫£n
                    stats = st.session_state.combined_df[selected_numeric_col].describe()
                    st.markdown("**Th·ªëng k√™ c∆° b·∫£n:**")
                    st.dataframe(stats)
                
                with col2:
                    # Bi·ªÉu ƒë·ªì ph√¢n b·ªë
                    fig_hist = px.histogram(
                        st.session_state.combined_df,
                        x=selected_numeric_col,
                        nbins=30,
                        title=f"Ph√¢n b·ªë {selected_numeric_col}"
                    )
                    st.plotly_chart(fig_hist, use_container_width=True)
        
        st.markdown("")  # Kho·∫£ng c√°ch
        
        # Th·ªëng k√™ theo nh√≥m
        st.markdown("### Th·ªëng k√™ theo nh√≥m")
        st.markdown("")  # Kho·∫£ng c√°ch
        
        # L·∫•y danh s√°ch c·ªôt c√≥ s·∫µn
        available_cols = [col for col in st.session_state.combined_df.columns 
                         if col not in ['Ngu·ªìn_File', 'Sheet']]
        
        group_col1, group_col2 = st.columns(2)
        
        with group_col1:
            group_by = st.selectbox(
                "Nh√≥m theo:",
                options=['Ngu·ªìn_File', 'Sheet'] + available_cols,
                key='group_by'
            )
        
        with group_col2:
            if numeric_columns:
                agg_column = st.selectbox(
                    "C·ªôt t√≠nh to√°n:",
                    options=numeric_columns,
                    key='agg_column'
                )
        
        if group_by and numeric_columns:
            if st.button("T√≠nh to√°n", type="primary"):
                if agg_column:
                    grouped_stats = st.session_state.combined_df.groupby(group_by)[agg_column].agg([
                        'count', 'sum', 'mean', 'median', 'std'
                    ]).round(2)
                    grouped_stats.columns = ['S·ªë l∆∞·ª£ng', 'T·ªïng', 'Trung b√¨nh', 'Trung v·ªã', 'ƒê·ªô l·ªách chu·∫©n']
                    st.dataframe(grouped_stats, use_container_width=True)
                    
                    # Bi·ªÉu ƒë·ªì c·ªôt
                    fig_bar = px.bar(
                        grouped_stats.reset_index(),
                        x=group_by,
                        y='T·ªïng',
                        title=f"T·ªïng {agg_column} theo {group_by}"
                    )
                    st.plotly_chart(fig_bar, use_container_width=True)
    elif st.session_state.dataframes:
        st.info("Vui l√≤ng t·ªïng h·ª£p d·ªØ li·ªáu tr∆∞·ªõc ·ªü tab 'T·ªïng h·ª£p'!")
    else:
        st.info("Vui l√≤ng t·∫£i l√™n c√°c file Excel ·ªü sidebar ƒë·ªÉ b·∫Øt ƒë·∫ßu!")

# Tab 4: Xu·∫•t b√°o c√°o
with tab4:
    st.header("Xu·∫•t B√°o c√°o")
    
    if st.session_state.combined_df is not None:
        st.subheader("Ch·ªçn d·ªØ li·ªáu ƒë·ªÉ xu·∫•t")
        
        export_option = st.radio(
            "Ch·ªçn d·ªØ li·ªáu:",
            options=['T·∫•t c·∫£ d·ªØ li·ªáu t·ªïng h·ª£p', 'K·∫øt qu·∫£ tra c·ª©u'],
            horizontal=True
        )
        
        if export_option == 'T·∫•t c·∫£ d·ªØ li·ªáu t·ªïng h·ª£p':
            export_df = st.session_state.combined_df
        else:
            if st.session_state.search_results is not None and not st.session_state.search_results.empty:
                export_df = st.session_state.search_results
            else:
                st.warning("Kh√¥ng c√≥ k·∫øt qu·∫£ tra c·ª©u ƒë·ªÉ xu·∫•t!")
                export_df = None
        
        if export_df is not None and not export_df.empty:
            st.info(f"S·∫Ω xu·∫•t {len(export_df)} d√≤ng d·ªØ li·ªáu")
            
            export_format = st.selectbox(
                "Ch·ªçn ƒë·ªãnh d·∫°ng:",
                options=['Excel (.xlsx)', 'CSV (.csv)']
            )
            
            filename = st.text_input(
                "T√™n file (kh√¥ng c·∫ßn ƒëu√¥i):",
                value=f"bao_cao_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            )
            
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("T·∫£i xu·ªëng", type="primary", use_container_width=True):
                    if export_format == 'Excel (.xlsx)':
                        file_data = export_to_excel(export_df, filename)
                        # T·ª± ƒë·ªông sao l∆∞u d·ªØ li·ªáu xu·∫•t
                        save_exported_data(export_df, 'excel')
                        st.download_button(
                            label="T·∫£i file Excel",
                            data=file_data,
                            file_name=f"{filename}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                    else:
                        file_data = export_to_csv(export_df)
                        # T·ª± ƒë·ªông sao l∆∞u d·ªØ li·ªáu xu·∫•t
                        save_exported_data(export_df, 'csv')
                        st.download_button(
                            label="T·∫£i file CSV",
                            data=file_data,
                            file_name=f"{filename}.csv",
                            mime="text/csv"
                        )
            
            with col2:
                st.markdown("### Xem tr∆∞·ªõc d·ªØ li·ªáu")
                st.dataframe(export_df.head(100), use_container_width=True, height=300)
    elif st.session_state.dataframes:
        st.info("Vui l√≤ng t·ªïng h·ª£p d·ªØ li·ªáu tr∆∞·ªõc ·ªü tab 'T·ªïng h·ª£p'!")
    else:
        st.info("Vui l√≤ng t·∫£i l√™n c√°c file Excel ·ªü sidebar ƒë·ªÉ b·∫Øt ƒë·∫ßu!")

# Footer
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: #666; padding: 1rem 0;'>"
    "·ª®ng d·ª•ng T·ªïng h·ª£p & Tra c·ª©u Excel | Powered by Streamlit"
    "</div>",
    unsafe_allow_html=True
)
